import os
import copy
import random
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from PIL import Image, ImageFile
from torchvision import transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

# â”€â”€ å…è®¸åŠ è½½æŸåçš„å›¾åƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ImageFile.LOAD_TRUNCATED_IMAGES = True

# â”€â”€ Efficient Channel Attention â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class ECABlock(nn.Module):
    def __init__(self, channels, k_size=3):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.conv     = nn.Conv1d(1, 1, kernel_size=k_size, padding=k_size//2, bias=False)
        self.sigmoid  = nn.Sigmoid()

    def forward(self, x):
        # x: [N, C, H, W]
        y = self.avg_pool(x)                                # [N, C, 1, 1]
        y = y.squeeze(-1).transpose(-1, -2)                 # [N, 1, C]
        y = self.conv(y)                                    # [N, 1, C]
        y = self.sigmoid(y).transpose(-1, -2).unsqueeze(-1)  # [N, C, 1, 1]
        return x * y.expand_as(x)                           # [N, C, H, W]

# â”€â”€ MCP-X æ¨¡å— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class MCPX(nn.Module):
    def __init__(self, in_ch, hid_ch, out_ch, num_paths):
        super().__init__()
        # å¤šè·¯åˆ†æ”¯ï¼šnum_paths ä¸ª 3Ã—3 Convâ†’BNâ†’ReLU
        self.paths = nn.ModuleList([
            nn.Sequential(
                nn.Conv2d(in_ch, hid_ch, kernel_size=3, padding=1),
                nn.BatchNorm2d(hid_ch),
                nn.ReLU(inplace=True)
            ) for _ in range(num_paths)
        ])
        # Expert Routingï¼šå…ˆåšå…¨å±€å¹³å‡æ± åŒ–ï¼Œå†ç”¨ 1Ã—1 Conv å¾—åˆ° num_paths ä¸ªæƒé‡ï¼Œæ¥ Softmax
        self.attn_weights = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(in_ch, num_paths, kernel_size=1),
            nn.Softmax(dim=1)
        )
        # å°†æ‰€æœ‰åˆ†æ”¯æ‹¼æ¥åç”¨ 1Ã—1 Convâ†’BNâ†’ReLU è¿˜åŸåˆ° out_ch
        self.merge_conv = nn.Sequential(
            nn.Conv2d(hid_ch * num_paths, out_ch, kernel_size=1),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True)
        )
        # é€šé“æ³¨æ„åŠ›
        self.eca      = ECABlock(out_ch)
        # æ®‹å·®å¿«æ·ï¼šå°† in_châ†’out_ch
        self.residual = nn.Conv2d(in_ch, out_ch, kernel_size=1)

    def forward(self, x):
        # x: [N, in_ch, H, W]
        w = self.attn_weights(x)  # [N, num_paths, 1, 1]
        outs = []
        for i, p in enumerate(self.paths):
            o  = p(x)                    # [N, hid_ch, H, W]
            wi = w[:, i:i+1, :, :].expand_as(o)
            outs.append(o * wi)          # å¸¦æƒé‡çš„åˆ†æ”¯è¾“å‡º
        cat    = torch.cat(outs, dim=1)  # [N, hid_ch * num_paths, H, W]
        merged = self.merge_conv(cat)    # [N, out_ch, H, W]
        attn   = self.eca(merged)        # [N, out_ch, H, W]
        return attn + self.residual(x)   # æ®‹å·®ç›¸åŠ 

# â”€â”€ å»æ‰ ECA çš„ MCP-Xï¼ˆä»…åšå¤šåˆ†æ”¯+è·¯ç”±+æ®‹å·®ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class MCPX_NoECA(nn.Module):
    def __init__(self, in_ch, hid_ch, out_ch, num_paths):
        super().__init__()
        self.paths = nn.ModuleList([
            nn.Sequential(
                nn.Conv2d(in_ch, hid_ch, kernel_size=3, padding=1),
                nn.BatchNorm2d(hid_ch),
                nn.ReLU(inplace=True)
            ) for _ in range(num_paths)
        ])
        self.attn_weights = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(in_ch, num_paths, kernel_size=1),
            nn.Softmax(dim=1)
        )
        self.merge_conv = nn.Sequential(
            nn.Conv2d(hid_ch * num_paths, out_ch, kernel_size=1),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True)
        )
        self.residual = nn.Conv2d(in_ch, out_ch, kernel_size=1)

    def forward(self, x):
        w = self.attn_weights(x)
        outs = []
        for i, p in enumerate(self.paths):
            o = p(x)
            wi = w[:, i:i+1, :, :].expand_as(o)
            outs.append(o * wi)
        cat    = torch.cat(outs, dim=1)
        merged = self.merge_conv(cat)
        # ç›´æ¥æ®‹å·®ç›¸åŠ ï¼Œä¸åš ECA
        return merged + self.residual(x)

# â”€â”€ MetaCortexNetï¼ˆå®Œæ•´ç‰ˆï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class MetaCortexNet(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        # Stage 1: æµ…å±‚ç¼–ç 
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.relu1 = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)
        self.relu2 = nn.ReLU(inplace=True)

        # Stage 2: MCP-X æ¨¡å—
        self.mcpx  = MCPX(in_ch=64, hid_ch=16, out_ch=64, num_paths=4)

        # Stage 3: BRSE è§£ç 
        self.enc1  = nn.Conv2d(64, 64, kernel_size=3, padding=1)
        self.relu3 = nn.ReLU(inplace=True)
        self.pool  = nn.MaxPool2d(2, 2)
        self.enc2  = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.relu4 = nn.ReLU(inplace=True)
        self.deconv= nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.relu5 = nn.ReLU(inplace=True)
        self.outc  = nn.Conv2d(64, 64, kernel_size=3, padding=1)
        self.relu6 = nn.ReLU(inplace=True)

        # Stage 4: Meta-Causal Attention
        self.attn_pool = nn.AdaptiveAvgPool2d((32, 32))
        self.attn      = nn.MultiheadAttention(embed_dim=64, num_heads=4, batch_first=True)

        # Stage 5: åˆ†ç±»å¤´
        self.gap       = nn.AdaptiveAvgPool2d((1, 1))
        self.fc_final  = nn.Linear(64, num_classes)

    def forward(self, x):
        N = x.size(0)
        # Stage 1
        x = self.relu1(self.conv1(x))  # [N, 32, 224, 224]
        x = self.relu2(self.conv2(x))  # [N, 64, 112, 112]
        # Stage 2
        x = self.mcpx(x)               # [N, 64, 112, 112]
        # Stage 3 (BRSE)
        x = self.relu3(self.enc1(x))   # [N, 64, 112, 112]
        x = self.pool(x)               # [N, 64, 56, 56]
        x = self.relu4(self.enc2(x))   # [N, 128, 56, 56]
        x = self.relu5(self.deconv(x)) # [N, 64, 112, 112]
        x = self.relu6(self.outc(x))   # [N, 64, 112, 112]
        # Stage 4 (Attention)
        x = self.attn_pool(x)          # [N, 64, 32, 32]
        C, H, W = x.shape[1:]
        x = x.view(N, C, H*W).permute(0, 2, 1)  # [N, H*W, C]
        x, _ = self.attn(x, x, x)      # [N, H*W, C]
        x = x.permute(0, 2, 1).view(N, C, H, W) # [N, 64, 32, 32]
        # Stage 5 (Classification)
        x = self.gap(x).view(N, -1)    # [N, 64]
        return self.fc_final(x)        # [N, num_classes]

# â”€â”€ åŸºçº¿æ¨¡å‹ï¼šå»æ‰ MCP-Xï¼Œåªä¿ç•™æµ…å±‚ + BRSE + Attention â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class BaselineNet(nn.Module):
    """
    Baselineï¼šè·³è¿‡ MCP-X æ¨¡å—
    """
    def __init__(self, num_classes):
        super().__init__()
        # Stage 1: æµ…å±‚ç¼–ç 
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.relu1 = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)
        self.relu2 = nn.ReLU(inplace=True)
        # è·³è¿‡ Stage 2 (MCP-X)

        # Stage 3: BRSE
        self.enc1  = nn.Conv2d(64, 64, kernel_size=3, padding=1)
        self.relu3 = nn.ReLU(inplace=True)
        self.pool  = nn.MaxPool2d(2, 2)
        self.enc2  = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.relu4 = nn.ReLU(inplace=True)
        self.deconv = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.relu5  = nn.ReLU(inplace=True)
        self.outc   = nn.Conv2d(64, 64, kernel_size=3, padding=1)
        self.relu6  = nn.ReLU(inplace=True)

        # Stage 4: Attention
        self.attn_pool = nn.AdaptiveAvgPool2d((32, 32))
        self.attn      = nn.MultiheadAttention(embed_dim=64, num_heads=4, batch_first=True)

        # Stage 5: åˆ†ç±»å¤´
        self.gap      = nn.AdaptiveAvgPool2d((1, 1))
        self.fc_final = nn.Linear(64, num_classes)

    def forward(self, x):
        N = x.size(0)
        x = self.relu1(self.conv1(x))  # [N, 32, 224, 224]
        x = self.relu2(self.conv2(x))  # [N, 64, 112, 112]
        # Stage 3 (BRSE)
        x = self.relu3(self.enc1(x))   # [N, 64, 112, 112]
        x = self.pool(x)               # [N, 64, 56, 56]
        x = self.relu4(self.enc2(x))   # [N, 128, 56, 56]
        x = self.relu5(self.deconv(x)) # [N, 64, 112, 112]
        x = self.relu6(self.outc(x))   # [N, 64, 112, 112]
        # Stage 4 (Attention)
        x = self.attn_pool(x)          # [N, 64, 32, 32]
        C, H, W = x.shape[1:]
        x = x.view(N, C, H*W).permute(0, 2, 1)  # [N, H*W, C]
        x, _ = self.attn(x, x, x)      # [N, H*W, C]
        x = x.permute(0, 2, 1).view(N, C, H, W) # [N, 64, 32, 32]
        # Stage 5 (Classification)
        x = self.gap(x).view(N, -1)    # [N, 64]
        return self.fc_final(x)        # [N, num_classes]

# â”€â”€ å»æ‰ Attention çš„ MetaCortexNet â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class MetaCortexNet_NoAttn(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.relu1 = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)
        self.relu2 = nn.ReLU(inplace=True)

        # MCP-Xï¼ˆå¯ä»¥æ›¿æ¢æˆ MCPX_NoECA æˆ– MCPXï¼Œæ ¹æ®éœ€è¦ï¼‰
        self.mcpx  = MCPX(in_ch=64, hid_ch=16, out_ch=64, num_paths=4)

        self.enc1  = nn.Conv2d(64, 64, kernel_size=3, padding=1)
        self.relu3 = nn.ReLU(inplace=True)
        self.pool  = nn.MaxPool2d(2,2)
        self.enc2  = nn.Conv2d(64,128, kernel_size=3, padding=1)
        self.relu4 = nn.ReLU(inplace=True)
        self.deconv= nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.relu5 = nn.ReLU(inplace=True)
        self.outc  = nn.Conv2d(64, 64, kernel_size=3, padding=1)
        self.relu6 = nn.ReLU(inplace=True)

        # å»æ‰äº† MultiheadAttention
        # self.attn_pool = nn.AdaptiveAvgPool2d((32,32))
        # self.attn      = nn.MultiheadAttention(embed_dim=64, num_heads=4, batch_first=True)

        self.gap      = nn.AdaptiveAvgPool2d((1,1))
        self.fc_final = nn.Linear(64, num_classes)

    def forward(self, x):
        N = x.size(0)
        x = self.relu1(self.conv1(x))  # [N, 32, 224,224]
        x = self.relu2(self.conv2(x))  # [N, 64, 112,112]
        x = self.mcpx(x)               # [N, 64, 112,112]
        x = self.relu3(self.enc1(x))   # [N, 64, 112,112]
        x = self.pool(x)               # [N, 64, 56, 56]
        x = self.relu4(self.enc2(x))   # [N,128, 56, 56]
        x = self.relu5(self.deconv(x)) # [N, 64,112,112]
        x = self.relu6(self.outc(x))   # [N, 64,112,112]
        # Stage4: ä¸åš Attention
        x = self.gap(x).view(N, -1)    # [N,64]
        return self.fc_final(x)        # [N, num_classes]

# â”€â”€ æ•°æ®åŠ è½½ï¼šæ”¯æŒå¯é…ç½®çš„ train/val/test åˆ’åˆ†æ¯”ä¾‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
mean = [0.485, 0.456, 0.406]
std  = [0.229, 0.224, 0.225]
train_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean, std)
])
test_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean, std)
])

def get_loaders(root, batch_size=16, random_state=42, split_ratio=(0.8, 0.1, 0.1)):
    """
    è¿”å› train/val/test DataLoaderï¼Œåˆ’åˆ†æ¯”ä¾‹ç”± split_ratio å†³å®šã€‚
    split_ratio: (train_frac, val_frac, test_frac)ï¼Œæ€»å’Œåº”ä¸º 1.0ã€‚
    """
    # 1) è½½å…¥æ•´ä¸ª ImageFolderï¼Œä¸æŒ‡å®š transform
    base = ImageFolder(root, transform=None)

    # 2) è¿‡æ»¤æ‰æŸåçš„å›¾åƒ
    good = []
    for p, lbl in base.samples:
        try:
            Image.open(p).verify()
            good.append((p, lbl))
        except Exception:
            print(f"âš ï¸ Skipping corrupted image: {p}")
    base.samples = good
    base.imgs = good

    total = len(good)
    labels = [lbl for _, lbl in good]
    idxs = list(range(total))

    train_frac, val_frac, test_frac = split_ratio
    tmp_frac = val_frac + test_frac

    # 3) å…ˆåˆ’åˆ† train vs tmp
    tr_idx, tmp_idx = train_test_split(
        idxs, test_size=tmp_frac, stratify=labels, random_state=random_state
    )

    # 4) åœ¨ tmp_idx ä¸­å†åˆ’åˆ† val vs test
    tmp_labels = [labels[i] for i in tmp_idx]
    val_ratio_over_tmp = val_frac / tmp_frac
    val_idx, tst_idx = train_test_split(
        tmp_idx, test_size=(test_frac / tmp_frac),
        stratify=tmp_labels, random_state=random_state
    )

    def make_loader(idxs, tfm, shuffle):
        ds = copy.deepcopy(base)
        ds.samples = [base.samples[i] for i in idxs]
        ds.imgs    = ds.samples
        ds.transform = tfm
        return DataLoader(ds, batch_size=batch_size, shuffle=shuffle)

    train_loader = make_loader(tr_idx, train_transforms, True)
    val_loader   = make_loader(val_idx,   test_transforms,  False)
    test_loader  = make_loader(tst_idx,   test_transforms,  False)
    return train_loader, val_loader, test_loader

# â”€â”€ è®­ç»ƒä¸è¯„ä¼°å‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def train_epoch(model, loader, device, optimizer, criterion):
    model.train()
    total_loss = 0.0
    correct = 0
    cnt = 0
    true_labels = []
    pred_labels = []

    for x, y in loader:
        x, y = x.to(device), y.to(device)
        optimizer.zero_grad()
        out = model(x)               # [batch_size, num_classes]
        loss = criterion(out, y)
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * x.size(0)
        preds = out.argmax(dim=1)
        correct += (preds == y).sum().item()
        cnt += x.size(0)

        true_labels.extend(y.cpu().tolist())
        pred_labels.extend(preds.cpu().tolist())

    avg_loss = total_loss / cnt
    accuracy = correct / cnt
    precision = precision_score(true_labels, pred_labels, average='macro', zero_division=0)
    recall    = recall_score   (true_labels, pred_labels, average='macro', zero_division=0)
    f1        = f1_score       (true_labels, pred_labels, average='macro', zero_division=0)
    return avg_loss, accuracy, precision, recall, f1

def evaluate(model, loader, device, criterion):
    model.eval()
    total_loss = 0.0
    correct = 0
    cnt = 0
    true_labels = []
    pred_labels = []

    with torch.no_grad():
        for x, y in loader:
            x, y = x.to(device), y.to(device)
            out = model(x)
            loss = criterion(out, y)

            total_loss += loss.item() * x.size(0)
            preds = out.argmax(dim=1)
            correct += (preds == y).sum().item()
            cnt += x.size(0)

            true_labels.extend(y.cpu().tolist())
            pred_labels.extend(preds.cpu().tolist())

    avg_loss = total_loss / cnt
    accuracy = correct / cnt
    precision = precision_score(true_labels, pred_labels, average='macro', zero_division=0)
    recall    = recall_score   (true_labels, pred_labels, average='macro', zero_division=0)
    f1        = f1_score       (true_labels, pred_labels, average='macro', zero_division=0)
    return avg_loss, accuracy, precision, recall, f1

# â”€â”€ è®¡ç®—æ¨¡å‹å‚æ•°é‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def count_parameters(model):
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    return total_params, trainable_params

# â”€â”€ ä¸»å‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    # â‘  ç”¨æˆ·å¯åœ¨æ­¤ä¿®æ”¹ï¼šé€‰æ‹©è¿è¡Œå“ªä¸€ç§æ¨¡å‹ç‰ˆæœ¬
    #    å¯é€‰å€¼ï¼š"fulmcl"ã€"no_mcp"ã€"no_eca"ã€"no_attn"
    MODEL_TYPE = "no_attn"  # "full" for MetaCortexNet, "no_mcp" for BaselineNet, "no_eca" for MCPX_NoECA, "no_attn" for MetaCortexNet_NoAtt
    # â‘¡ å¯åœ¨æ­¤ä¿®æ”¹ï¼šæ˜¯å¦å¯¹æ¯”ä¸åŒæ•°æ®åˆ’åˆ†æ¯”ä¾‹ã€‚è‹¥åªæƒ³è·‘å•ä¸€åˆ’åˆ†ï¼Œç›´æ¥æ³¨é‡Š for å¾ªç¯éƒ¨åˆ†å³å¯ã€‚
    split_list = [(0.8, 0.1, 0.1)]

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ Using device: {device}")

    dataset_root = r"C:\Users\wku\Documents\GitHub\riceleaftestdataset\archive4\plantvillage dataset\color" # â† å°†æ­¤å¤„æ”¹ä¸ºä½ çš„ PlantVillage æ•°æ®é›†æ ¹ç›®å½•

    results = []  # ç”¨äºè®°å½•ä¸åŒåˆ’åˆ†ä¸‹çš„æœ€ç»ˆè¡¨ç°

    for split_ratio in split_list:
        print(f"\n==================== Split: {split_ratio} ====================")
        # åŠ è½½æ•°æ®
        train_loader, val_loader, test_loader = get_loaders(
            dataset_root, batch_size=16, random_state=42, split_ratio=split_ratio
        )
        num_classes = len(train_loader.dataset.classes)
        print(f"ğŸ“¦ ç±»åˆ«æ•°: {num_classes}")
        print(f"ğŸš† train batches: {len(train_loader)}, val batches: {len(val_loader)}, test batches: {len(test_loader)}")

        # æ ¹æ® MODEL_TYPE å®ä¾‹åŒ–æ¨¡å‹
        if MODEL_TYPE == "full":
            model = MetaCortexNet(num_classes=num_classes)
        elif MODEL_TYPE == "no_mcp":
            model = BaselineNet(num_classes=num_classes)
        elif MODEL_TYPE == "no_eca":
            # åˆ›å»ºä¸€ä¸ªä¸´æ—¶å­ç±»ï¼Œå°† MCPX æ›¿æ¢ä¸º MCPX_NoECA
            class MetaCortexNet_NoECA(MetaCortexNet):
                def __init__(self, num_classes):
                    super().__init__(num_classes)
                    self.mcpx = MCPX_NoECA(in_ch=64, hid_ch=16, out_ch=64, num_paths=4)
            model = MetaCortexNet_NoECA(num_classes=num_classes)
        elif MODEL_TYPE == "no_attn":
            model = MetaCortexNet_NoAttn(num_classes=num_classes)
        else:
            raise ValueError(f"Unknown MODEL_TYPE: {MODEL_TYPE}")

        model = model.to(device)

        # è¾“å‡ºå‚æ•°é‡
        total_params, trainable_params = count_parameters(model)
        print(f"ğŸ“ Model params: total={total_params:,}, trainable={trainable_params:,}")

        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=1e-3)

        best_val_f1 = 0.0
        best_state = None

        # è®­ç»ƒå¾ªç¯
        for epoch in range(1, 101):  # æœ€å¤š 50 è½®
            t_loss, t_acc, t_prec, t_rec, t_f1 = train_epoch(model, train_loader, device, optimizer, criterion)
            v_loss, v_acc, v_prec, v_rec, v_f1 = evaluate(model, val_loader, device, criterion)

            print(f"[Split {split_ratio}, Epoch {epoch:02d}] "
                  f"Train â†’ Loss: {t_loss:.4f}, Acc: {t_acc:.2%}, Prec: {t_prec:.2%}, Rec: {t_rec:.2%}, F1: {t_f1:.2%} | "
                  f"Val   â†’ Loss: {v_loss:.4f}, Acc: {v_acc:.2%}, Prec: {v_prec:.2%}, Rec: {v_rec:.2%}, F1: {v_f1:.2%}")

            # æ—©åœï¼šå¦‚æœéªŒè¯ F1 æ›´å¥½ï¼Œåˆ™ä¿å­˜å½“å‰å‚æ•°
            if v_f1 > best_val_f1:
                best_val_f1 = v_f1
                best_state = copy.deepcopy(model.state_dict())
                # ä¿å­˜æ¨¡å‹ï¼Œæ–‡ä»¶åå¯è‡ªå®šä¹‰
                model_save_name = f"best_model_no_attn_{int(split_ratio[0]*100)}_{int(split_ratio[1]*100)}_{int(split_ratio[2]*100)}_{MODEL_TYPE}_{epoch}.pth"
                torch.save(best_state, model_save_name)
                print(f"âœ… New best model saved on validation F1: {model_save_name}")

        # åŠ è½½æœ€ä½³å‚æ•°ååœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
        model.load_state_dict(best_state)
        test_loss, test_acc, test_prec, test_rec, test_f1 = evaluate(model, test_loader, device, criterion)
        print(f"\nğŸ¯ Final Test â†’ Loss: {test_loss:.4f}, Acc: {test_acc:.2%}, Prec: {test_prec:.2%}, Rec: {test_rec:.2%}, F1: {test_f1:.2%}\n")

        # ç”Ÿæˆå¹¶ä¿å­˜æ··æ·†çŸ©é˜µå›¾åƒ
        all_true, all_pred = [], []
        model.eval()
        with torch.no_grad():
            for x, y in test_loader:
                x, y = x.to(device), y.to(device)
                out = model(x)
                preds = out.argmax(dim=1)
                all_true.extend(y.cpu().tolist())
                all_pred.extend(preds.cpu().tolist())
        cm = confusion_matrix(all_true, all_pred)
        # æ‰“å°æ··æ·†çŸ©é˜µæ•°å€¼ï¼ˆå®Œæ•´æ˜¾ç¤ºï¼Œä¸çœç•¥ï¼‰
        np.set_printoptions(threshold=np.inf, linewidth=200)
        print("æ··æ·†çŸ©é˜µæ•°å€¼:")
        print(cm.tolist())
        plt.figure(figsize=(8, 6))
        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
        plt.title(f'Confusion Matrix Split {split_ratio}')
        plt.colorbar()
        tick_marks = np.arange(num_classes)
        plt.xticks(tick_marks, train_loader.dataset.classes, rotation=45)
        plt.yticks(tick_marks, train_loader.dataset.classes)
        plt.ylabel('True label')
        plt.xlabel('Predicted label')
        plt.tight_layout()
        cm_filename = f"confusion_matrix_{int(split_ratio[0]*100)}_{int(split_ratio[1]*100)}_{int(split_ratio[2]*100)}.png"
        plt.savefig(cm_filename)
        print(f"ğŸ¨ Confusion matrix saved to {cm_filename}\n")
        
        results.append({
            "split": split_ratio,
            "test_acc": test_acc,
            "test_prec": test_prec,
            "test_rec": test_rec,
            "test_f1": test_f1,
            "params": total_params
        })

    # è¾“å‡ºæ‰€æœ‰ç»“æœæ±‡æ€»
    print("\n==================== Summary ====================")
    for res in results:
        print(f"Split {res['split']} | "
              f"Test Acc={res['test_acc']:.2%} | "
              f"Test Prec={res['test_prec']:.2%} | "
              f"Test Rec={res['test_rec']:.2%} | "
              f"Test F1={res['test_f1']:.2%} | "
              f"Params={res['params']:,}")

if __name__ == "__main__":
    main()
